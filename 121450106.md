# Nama : Rangga Adi Putra
# NIM : 121450106
# Kelas : RB


# Setup
## A Dataset to Play With
Dataset CIFAR-10 terdiri dari 60.000 gambar berwarna dengan resolusi 32x32 piksel, terbagi dalam sepuluh kategori objek seperti anjing, kucing, dan pesawat. Bagian dari kumpulan data TinyImages yang lebih besar, CIFAR-10 bisa diunduh dalam versi Python melalui tautan di artikel, membutuhkan sekitar 163MB ruang disk. Setelah diunduh dan diekstrak, file-file dataset tidak dalam format gambar yang langsung dapat dilihat, melainkan diserialisasi dan disimpan dalam batch menggunakan cPickle. Untuk memuat dataset ke dalam array NumPy, gunakan kode Python untuk mengurai ("unpickle") setiap file batch, mengubahnya menjadi format yang dapat diproses oleh program. Meskipun artikel tidak mendetailkan penggunaan pickle atau cPickle, modul ini memudahkan serialisasi dan deserialisasi objek Python.

## Setup for Storing Images on Disk
  ```
  pip install pillow
  ```
![alt text](image-1.png)

## Getting Started With LMDB
  ```
  pip install lmdb
  ```
![alt text](image-2.png)

## Getting Started With HDF5
  ```
  pip install h5py
  ```
![alt text](image-3.png)

# Storing a Single Image
**Membuat Direktori untuk Setiap Metode Penyimpanan**:  
   ```bash
   mkdir data/disk
   mkdir data/lmdb
   mkdir data/hdf5
   ```
**Menyimpan Jalur Direktori ke dalam Variabel Python**:
```python
from pathlib import Path
disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
Dengan menggunakan dataset CIFAR-10 yang terdiri dari 50.000 gambar, gandakan setiap gambar sehingga total menjadi 100.000 gambar untuk eksperimen. Bandingkan kinerja berbagai metode penyimpanan dengan menguji jumlah gambar yang berbeda-beda, mulai dari satu gambar hingga 100.000 gambar.

## Storing to Disk
**Simpan Gambar ke Disk**
```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

**Simpan Meta Data**
Ada beberapa pendekatan yang dapat dipertimbangkan untuk menyimpan metadata, seperti label, yang terkait dengan gambar. Salah satu metode adalah dengan menyertakan label dalam nama file gambar itu sendiri. Pendekatan ini menghindari kebutuhan membuat file tambahan, namun dapat membuat pengelolaan file menjadi lebih rumit. Alternatif lain adalah menyimpan label dalam file terpisah. Anda dapat membuat file dengan format `.csv` (Comma-Separated Values) untuk menyimpan label. Pendekatan ini memungkinkan pengelolaan label tanpa harus memuat seluruh gambar, yang bisa lebih efisien dalam penggunaan sumber daya.

## Storing to LMDB
**LMDB (Lightning Memory-Mapped Database)** LMDB merupakan sistem penyimpanan kunci-nilai yang menyimpan setiap entri data sebagai array byte. Kunci bertindak sebagai pengenal unik untuk setiap gambar, sedangkan nilai adalah data gambar yang diserialisasi menjadi string. Ketika gambar dibaca dari database, data string tersebut dideserialisasi kembali ke format aslinya, seperti array NumPy atau objek gambar. LMDB menyediakan penyimpanan data yang efisien dengan pasangan kunci-nilai.

**Gunakan modul `pickle` untuk melakukan serialisasi**. Modul `pickle` di Python digunakan untuk serialisasi objek Python ke format byte yang dapat disimpan atau dikirim. Dengan `pickle`, Anda dapat menyerialisasi data gambar dan metadata terkait ke format yang dapat disimpan dalam basis data. Menyimpan metadata bersama dengan data gambar dalam basis data menghilangkan kebutuhan untuk melakukan mapping antara gambar dan metadata saat memuat dataset dari disk. Hal ini menyederhanakan proses pemuatan data dan memastikan integritas antara gambar dan metadata. Dengan demikian, penggunaan `pickle` untuk serialisasi dan penyimpanan metadata bersama data gambar mempermudah pengelolaan dan pemuatan dataset.

**Membuat Kelas Python untuk Gambar dan Meta Data**
```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
**Menetapkan Ukuran Peta**
Langkah penting dalam penggunaan LMDB (Lightning Memory-Mapped Database) adalah menentukan jumlah memori yang akan digunakan karena LMDB menggunakan teknik memori-mapped untuk pengelolaan data. Untuk memastikan efisiensi alokasi dan pengelolaan memori, estimasi jumlah memori yang akan digunakan oleh database perlu dilakukan. Variabel `map_size` digunakan untuk menetapkan ukuran maksimum ruang alamat memori yang akan dimapping untuk LMDB. Dengan mengatur `map_size`, batasan memori yang digunakan oleh LMDB untuk menyimpan data dapat dikontrol, mencegah alokasi memori yang tidak efisien, dan memastikan performa optimal. Estimasi awal jumlah memori yang dibutuhkan untuk menyimpan seluruh data yang akan dimasukkan ke dalam database diperlukan sebelum menggunakan LMDB. Estimasi ini digunakan untuk mengonfigurasi variabel `map_size` sesuai kebutuhan, memungkinkan.

**Operasi Transaksi**
```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```


## Storing With HDF5
Pemahaman dan pengelolaan penyimpanan data dengan file HDF5 melibatkan beberapa langkah penting. File ini mampu menyimpan lebih dari satu dataset, memungkinkan efisiensi dalam penyimpanan berbagai jenis data. Dalam konteks penyimpanan gambar dan metadata terkait, diperlukan pembuatan dua dataset terpisah dalam satu file HDF5: satu untuk gambar dan satu lagi untuk metadata gambar. Gunakan `h5py.h5t.STD_U8BE` untuk menentukan tipe data dalam dataset, yang cocok untuk menyimpan nilai pixel gambar. Pastikan tipe data yang dipilih memenuhi kebutuhan minimal untuk memaksimalkan efisiensi penyimpanan dan pemrosesan data.


```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

## Experiments for Storing a Single Image
**Menyiapkan Fungsi Penyimpanan**
```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

**Melakukan Eksperimen Waktu**
```python
from timeit import timeit
store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
**Hasil Eksperimen**
![alt text](image-4.png)

# Storing Many Images
## Adjusting the Code for Many Images
```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
## Preparing the Dataset 
```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```
## Experiment for Storing Many Images
```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
Harap bersabar sejenak dan tunggu dengan penuh antusiasme sementara 111.110 gambar disimpan tiga kali masing-masing ke dalam disk Anda, dalam tiga format yang berbeda. Anda juga harus siap mengucapkan selamat tinggal pada sekitar 2 GB ruang disk.

Grafik pertama menunjukkan waktu penyimpanan normal, tanpa penyesuaian, menyoroti perbedaan drastis antara menyimpan ke file .png dan ke LMDB atau HDF5.
![alt text](image-5.png)
Grafik kedua menunjukkan log dari waktu yang diukur, menyoroti bahwa HDF5 mulai lebih lambat dari LMDB tetapi, dengan jumlah gambar yang lebih besar, akhirnya sedikit lebih unggul.
![alt text](image-6.png)


# Reading a Single Image
## Reading From Disk
```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```
## Reading From LMDB
```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

## Reading From HDF5
```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image
        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label

_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

## Experiment for Reading a Single Image
```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
**Hasil Eksperimen**
![alt text](image-7.png)

## Kesimpulan
Membaca file .png dan .csv langsung dari disk sedikit lebih cepat dibandingkan dengan metode penyimpanan seperti LMDB atau HDF5 karena operasi langsung dari sistem file disk umumnya cukup cepat. Meskipun demikian, secara keseluruhan, semua metode penyimpanan (disk, LMDB, dan HDF5) memberikan performa yang hampir sama dan cepat. Perbedaan kecepatan antara ketiga metode dianggap tidak signifikan, sehingga perbedaan kecepatan dalam pembacaan langsung dari disk tidak menjadi faktor penentu dalam pemilihan metode penyimpanan.

Analisis grafik menunjukkan bahwa meskipun awalnya mungkin lebih lambat, metode HDF5 menunjukkan peningkatan performa yang signifikan seiring dengan peningkatan jumlah gambar. Ini menunjukkan keunggulan HDF5 dalam pembacaan batch gambar yang besar. Perbedaan antara metode penyimpanan menjadi lebih jelas saat menggunakan jumlah gambar yang lebih besar, namun tidak begitu terlihat saat jumlah gambar lebih sedikit.